{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1OnohC0_RT86R1MR7uqkp4XmdCV8Gqx1N","timestamp":1690161477273}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["In this assignment, you will perform three NLP tasks using Hugging Face tokenizers, models, and pipelines. The goal is to learn:\n","\n","- How to use Hugging Face tokenizers for preprocessing tasks like padding, truncation, and batching of text.\n","\n","- How model configuration works, including mapping between id2label and label2id for token classification tasks.\n","\n","- How Hugging Face models work, including passing text through the model to generate logits.\n","\n","- How to use the logits output from Hugging Face models to make predictions for your NLP task.\n","\n","- How to recreate Hugging Face pipelines by using the tokenizers and models directly, instead of relying on the pipelines.\n","\n","- Compare the results of using the tokenizers and models directly versus using the Hugging Face pipelines to evaluate the differences.\n","\n","The focus of this assignment is gaining hands-on experience with Hugging Face tokenizers, configuration, models, and pipelines through implementing three text processing tasks end-to-end. This will provide a deeper understanding of how these key NLP components work."],"metadata":{"id":"SL9Sl3TlF74C"}},{"cell_type":"markdown","source":["# Installing Core NLP Libraries\n","\n","This section installs 3 key libraries for NLP and ML projects:\n","\n","- Transformers - Provides access to pretrained models like BERT, RoBERTa for NLP.\n","\n","- Datasets - Provides convenient access to common NLP datasets.\n","\n","- Rich - For nicely formatted console output when training models.\n","\n","Installing these libraries in one line allows quick setup of the Python environment with critical functionality for working on text data.\n"],"metadata":{"id":"yMR3yJ5bFB6q"}},{"cell_type":"code","source":["!pip install transformers datasets rich"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VvRBEfGwG3xl","executionInfo":{"status":"ok","timestamp":1694211812672,"user_tz":300,"elapsed":19047,"user":{"displayName":"Biswajit Khara","userId":"04998448106830231172"}},"outputId":"d0ad8a14-00d5-47cd-cb96-b821e37045f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets\n","  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (13.5.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich) (2.16.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: tokenizers, safetensors, xxhash, dill, multiprocess, huggingface-hub, transformers, datasets\n","Successfully installed datasets-2.14.5 dill-0.3.7 huggingface-hub-0.16.4 multiprocess-0.70.15 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.1 xxhash-3.3.0\n"]}]},{"cell_type":"markdown","source":["The transformers.pipeline() method provides quick access to pretrained NLP models for making predictions. The rich.pretty.pprint() method prints Python objects to the console in a readable formatted way."],"metadata":{"id":"ShprEl7DISw8"}},{"cell_type":"code","source":["from transformers import pipeline\n","from rich.pretty import pprint\n","import torch.nn.functional as F\n","import torch"],"metadata":{"id":"ZMc0V7uoG6Fi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here is documentation for each section of the notebook:\n","\n","\n","\n","\n","# Summary\n","\n","By walking through the pipeline components, this shows how to go from raw text to formatted predictions step-by-step. This provides more visibility than just using the packaged pipeline."],"metadata":{"id":"rbMpxGxuMU_1"}},{"cell_type":"markdown","source":[],"metadata":{"id":"Sp8xNYwuMsQQ"}},{"cell_type":"markdown","source":["# Creating a Text Classification Pipeline\n","\n","This section creates a text classification pipeline using Hugging Face's transformers library. The pipeline gives quick access to a pretrained DistilBERT model finetuned on the SST-2 sentiment analysis dataset.\n","\n","The pipeline makes predictions on some sample text, returning the sentiment label and score for each sentence."],"metadata":{"id":"EiQDjpkwMxOY"}},{"cell_type":"code","source":["classification = pipeline(task=\"text-classification\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xcag9ZH0HY0h","executionInfo":{"status":"ok","timestamp":1694215239164,"user_tz":300,"elapsed":763,"user":{"displayName":"Biswajit Khara","userId":"04998448106830231172"}},"outputId":"25b982dd-4575-4cf0-b595-dd74128984a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n"]}]},{"cell_type":"code","source":["raw_inputs = [\n","    \"I've been waiting for a HuggingFace course my whole life.\",\n","    \"I hate this so much!\",\n","]\n","results = classification(raw_inputs)\n","pprint(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"5v_R0IjAHzFS","executionInfo":{"status":"ok","timestamp":1694212248970,"user_tz":300,"elapsed":373,"user":{"displayName":"Biswajit Khara","userId":"04998448106830231172"}},"outputId":"2aa87c87-ab0b-46a4-aaba-b2d3cc5114e7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'label'\u001b[0m: \u001b[32m'POSITIVE'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9598048329353333\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[32m'label'\u001b[0m: \u001b[32m'NEGATIVE'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9994558691978455\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'POSITIVE'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9598048329353333</span><span style=\"font-weight: bold\">}</span>, <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'NEGATIVE'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9994558691978455</span><span style=\"font-weight: bold\">}]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":[],"metadata":{"id":"rOW8wjqjM4Sw"}},{"cell_type":"markdown","source":["# Loading Tokenizer, Config, and Model\n","\n","This section loads the lower-level components used by the pipeline:\n","\n","- Tokenizer: Preprocesses the text into ids, handles padding/truncation.\n","\n","- Config: Contains model configuration like hyperparams and mapping from ids to labels.\n","\n","- Model: The core Transformer model like DistilBERT that generates embeddings and predictions.\n","\n","Loading these separately gives more control than just using the packaged pipeline.\n"],"metadata":{"id":"VAeGzjLQM88m"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification"],"metadata":{"id":"Xp8gwNjII7Ed"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\""],"metadata":{"id":"cCPuumasH7yZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","config = AutoConfig.from_pretrained(checkpoint)\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"],"metadata":{"id":"bPKWeLD6I-GE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","# Tokenizing the Text\n","\n","The tokenizer is used to preprocess the raw text into tokenized ids with padding & truncation to fit the expected model input shape.\n","\n","This shows how the tokenizer prepares the data before passing it to the model.\n"],"metadata":{"id":"Ts_jL7RVNGU5"}},{"cell_type":"code","source":["inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n","pprint(inputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":153},"id":"rXOtZO2HJAwy","executionInfo":{"status":"ok","timestamp":1694215058009,"user_tz":300,"elapsed":111,"user":{"displayName":"Biswajit Khara","userId":"04998448106830231172"}},"outputId":"9500e69a-b42d-4454-bd26-0cbc5580d074"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1m{\u001b[0m\n","\u001b[2;32m│   \u001b[0m\u001b[32m'input_ids'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[1;36m101\u001b[0m,  \u001b[1;36m1045\u001b[0m,  \u001b[1;36m1005\u001b[0m,  \u001b[1;36m2310\u001b[0m,  \u001b[1;36m2042\u001b[0m,  \u001b[1;36m3403\u001b[0m,  \u001b[1;36m2005\u001b[0m,  \u001b[1;36m1037\u001b[0m, \u001b[1;36m17662\u001b[0m, \u001b[1;36m12172\u001b[0m,\n","\u001b[2;32m│   │     \u001b[0m\u001b[1;36m2607\u001b[0m,  \u001b[1;36m2026\u001b[0m,  \u001b[1;36m2878\u001b[0m,  \u001b[1;36m2166\u001b[0m,  \u001b[1;36m1012\u001b[0m,   \u001b[1;36m102\u001b[0m\u001b[1m]\u001b[0m,\n","\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m  \u001b[1;36m101\u001b[0m,  \u001b[1;36m1045\u001b[0m,  \u001b[1;36m5223\u001b[0m,  \u001b[1;36m2023\u001b[0m,  \u001b[1;36m2061\u001b[0m,  \u001b[1;36m2172\u001b[0m,   \u001b[1;36m999\u001b[0m,   \u001b[1;36m102\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,\n","\u001b[2;32m│   │   │    \u001b[0m\u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[32m'attention_mask'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,\n","\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n","\u001b[1m}\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'input_ids'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1045</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1005</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2310</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2042</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3403</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2005</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1037</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17662</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12172</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2607</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2026</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2878</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2166</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1012</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span><span style=\"font-weight: bold\">]</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1045</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5223</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2061</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2172</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">999</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │    </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]])</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'attention_mask'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]])</span>\n","<span style=\"font-weight: bold\">}</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["# Printing Truncated Text\n","\n","The truncated input text is decoded back to readable text using the tokenizer's decode method.\n","\n","This shows how padding and truncation end up masking part of the original input.\n"],"metadata":{"id":"8uPhUVnqNN0A"}},{"cell_type":"code","source":["pprint(tokenizer.decode(inputs[\"input_ids\"][0]))\n","pprint(tokenizer.decode(inputs[\"input_ids\"][1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"id":"FZiAHRRFJOjR","executionInfo":{"status":"ok","timestamp":1694213409077,"user_tz":300,"elapsed":128,"user":{"displayName":"Biswajit Khara","userId":"04998448106830231172"}},"outputId":"cd384458-6e93-487c-ea72-e77cbeec382a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32mCLS\u001b[0m\u001b[32m]\u001b[0m\u001b[32m i've been waiting for a huggingface course my whole life. \u001b[0m\u001b[32m[\u001b[0m\u001b[32mSEP\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\"[CLS] i've been waiting for a huggingface course my whole life. [SEP]\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mCLS\u001b[0m\u001b[32m]\u001b[0m\u001b[32m i hate this so much! \u001b[0m\u001b[32m[\u001b[0m\u001b[32mSEP\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mPAD\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mPAD\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mPAD\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mPAD\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mPAD\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mPAD\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mPAD\u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32mPAD\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'[CLS] i hate this so much! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["# Passing Inputs to Model\n","\n","The tokenized & padded inputs are passed to the model to generate predictions.\n","\n","This uses the model directly instead of the pipeline, giving more control."],"metadata":{"id":"7wWAUu6r83gK"}},{"cell_type":"code","source":["outputs = model(**inputs)\n","pprint(outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136},"id":"UJm4UNCH_Y1Q","executionInfo":{"status":"ok","timestamp":1694215158982,"user_tz":300,"elapsed":197,"user":{"displayName":"Biswajit Khara","userId":"04998448106830231172"}},"outputId":"b9abcf2b-e46f-4ed1-dd1c-9275eb51be33"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1;35mSequenceClassifierOutput\u001b[0m\u001b[1m(\u001b[0m\n","\u001b[2;32m│   \u001b[0m\u001b[33mloss\u001b[0m=\u001b[3;35mNone\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mlogits\u001b[0m=\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1.5607\u001b[0m,  \u001b[1;36m1.6123\u001b[0m\u001b[1m]\u001b[0m,\n","\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m4.1692\u001b[0m, \u001b[1;36m-3.3464\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mAddmmBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mhidden_states\u001b[0m=\u001b[3;35mNone\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[33mattentions\u001b[0m=\u001b[3;35mNone\u001b[0m\n","\u001b[1m)\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SequenceClassifierOutput</span><span style=\"font-weight: bold\">(</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">loss</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">logits</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.5607</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.6123</span><span style=\"font-weight: bold\">]</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.1692</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.3464</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">AddmmBackward0</span><span style=\"font-weight: bold\">&gt;)</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">hidden_states</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">attentions</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n","<span style=\"font-weight: bold\">)</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["# Interpreting Model Outputs\n","\n","This happens in two steps:\n","\n","1. The raw numeric tensor outputs of the model are converted into probability scores and sentiment labels.\n","\n","2. This uses the mapping in the config to go from indices predicted by the model back to the associated labels.\n"],"metadata":{"id":"OD8BLmSdNS9F"}},{"cell_type":"markdown","source":["## Covert logits to probabilities"],"metadata":{"id":"UMiBV9N5NXS9"}},{"cell_type":"code","source":["predictions = F.softmax(outputs.logits, dim=-1)\n","pprint(predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"id":"AkPIG6J8Jfd_","executionInfo":{"status":"ok","timestamp":1694213637669,"user_tz":300,"elapsed":95,"user":{"displayName":"Biswajit Khara","userId":"04998448106830231172"}},"outputId":"5d6d02d3-fd27-4e7c-a2f3-98870e64c8c1"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m4.0195e-02\u001b[0m, \u001b[1;36m9.5980e-01\u001b[0m\u001b[1m]\u001b[0m,\n","\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m9.9946e-01\u001b[0m, \u001b[1;36m5.4418e-04\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mSoftmaxBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.0195e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.5980e-01</span><span style=\"font-weight: bold\">]</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.9946e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.4418e-04</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">SoftmaxBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Loop through probabilities and convert to interpretable results"],"metadata":{"id":"D5axmOUCNdyN"}},{"cell_type":"code","source":["result = []\n","for index, prediction in enumerate(predictions):\n","  probability = torch.max(prediction).item()\n","  sentiment = config.id2label[torch.argmax(prediction).item()]\n","  result.append({\"probability\": probability, \"label\": sentiment})\n","pprint(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"id":"439dHeOmKFjp","executionInfo":{"status":"ok","timestamp":1694214106978,"user_tz":300,"elapsed":130,"user":{"displayName":"Biswajit Khara","userId":"04998448106830231172"}},"outputId":"70b4a1a7-6252-4935-c245-33e31f4305c6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1m[\u001b[0m\n","\u001b[2;32m│   \u001b[0m\u001b[1m{\u001b[0m\u001b[32m'probability'\u001b[0m: \u001b[1;36m0.9598048329353333\u001b[0m, \u001b[32m'label'\u001b[0m: \u001b[32m'POSITIVE'\u001b[0m\u001b[1m}\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[1m{\u001b[0m\u001b[32m'probability'\u001b[0m: \u001b[1;36m0.9994558691978455\u001b[0m, \u001b[32m'label'\u001b[0m: \u001b[32m'NEGATIVE'\u001b[0m\u001b[1m}\u001b[0m\n","\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9598048329353333</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'POSITIVE'</span><span style=\"font-weight: bold\">}</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9994558691978455</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'NEGATIVE'</span><span style=\"font-weight: bold\">}</span>\n","<span style=\"font-weight: bold\">]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["The end result matches what the pipeline originally produced (compare with the pipeline results)"],"metadata":{"id":"NFkVtShVRIdQ"}},{"cell_type":"markdown","source":["# EXERCISE 1\n","\n","Write the code for analyzing the sentiment of the same raw_inputs using the model \"cardiffnlp/twitter-roberta-base-sentiment\"\n","\n"],"metadata":{"id":"0V8rQK-9DQw4"}},{"cell_type":"code","source":["raw_inputs = [\n","    \"I've been waiting for a HuggingFace course my whole life.\",\n","    \"I hate this so much!\",\n","]\n","\n","checkpoint = \"cardiffnlp/twitter-roberta-base-sentiment\"\n","\n","# Complete the codes for each of the task below\n","\n","# initialize tokenizer\n","# initialize config\n","# initialize model\n","# create inputs for the model (from raw inputs)\n","# get model outputs\n","# convert logits to probabilities\n","# get the labels for each item\n","# print the result\n","# Now, use pipeline to do the same task\n","# compare the results"],"metadata":{"id":"KNy8Z8QkONuX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# EXERCISE 2\n","* Finish the (unfinished) commented codes below\n","* Instructions start with \"##\""],"metadata":{"id":"zDwXMw7BRGuR"}},{"cell_type":"markdown","source":["# Creating a Token Classification Pipeline\n","\n","This section creates a named entity recognition (NER) pipeline using the Hugging Face transformers library. The pipeline provides quick access to a pretrained BERT model finetuned on the CoNLL 2003 NER dataset.\n","\n","The pipeline makes predictions on a sample input text, returning the predicted NER tags with scores for each token.\n"],"metadata":{"id":"DIZ2uXcwROrq"}},{"cell_type":"code","source":["## Create a token classifier using pipeline\n","# token_classifier ="],"metadata":{"id":"xtfduFt8KNsC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Inspecting the Pipeline Output\n","\n","The raw JSON output from the NER pipeline is printed to inspect the predicted entity, score, index, word, start and end values for each tagged token."],"metadata":{"id":"41KiWT4zaQtB"}},{"cell_type":"code","source":["ner_raw_inputs = \"My name is Wolfgang and I live in Berlin\"\n","# result =\n","# pprint(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83},"id":"_pT5v6bURTwt","executionInfo":{"status":"ok","timestamp":1689992931437,"user_tz":420,"elapsed":817,"user":{"displayName":"Santi Adavani","userId":"01589529678393192778"}},"outputId":"a0dd4020-2a7f-4aaf-b295-bcf7696c3443"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1m[\u001b[0m\n","\u001b[2;32m│   \u001b[0m\u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-PER'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.99914825\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m4\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'Wolfgang'\u001b[0m, \u001b[32m'start'\u001b[0m: \u001b[1;36m11\u001b[0m, \u001b[32m'end'\u001b[0m: \u001b[1;36m19\u001b[0m\u001b[1m}\u001b[0m,\n","\u001b[2;32m│   \u001b[0m\u001b[1m{\u001b[0m\u001b[32m'entity'\u001b[0m: \u001b[32m'I-LOC'\u001b[0m, \u001b[32m'score'\u001b[0m: \u001b[1;36m0.9983669\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1;36m9\u001b[0m, \u001b[32m'word'\u001b[0m: \u001b[32m'Berlin'\u001b[0m, \u001b[32m'start'\u001b[0m: \u001b[1;36m34\u001b[0m, \u001b[32m'end'\u001b[0m: \u001b[1;36m40\u001b[0m\u001b[1m}\u001b[0m\n","\u001b[1m]\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-PER'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.99914825</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Wolfgang'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span><span style=\"font-weight: bold\">}</span>,\n","<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'entity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I-LOC'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9983669</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'word'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Berlin'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span><span style=\"font-weight: bold\">}</span>\n","<span style=\"font-weight: bold\">]</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["# Loading the Pipeline Components\n","\n","The lower level tokenizer, config, and model objects that compose the pipeline are loaded. This gives more control than just using the packaged pipeline.\n"],"metadata":{"id":"leUltJ7NaVvl"}},{"cell_type":"code","source":["ner_checkpoint = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n","# ner_tokenizer =\n","# pprint(ner_tokenizer)"],"metadata":{"id":"HWblGxnlReEL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Tokenizing the Input\n","\n","The tokenizer preprocesses the raw text into tokenized ids, padding & truncating as needed to match the expected model input shape.\n"],"metadata":{"id":"unMzfgTead_I"}},{"cell_type":"code","source":["# ner_model_inputs ="],"metadata":{"id":"2eC9_r9ySFC3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Passing Inputs to the Model\n","\n","The tokenized inputs are passed to the model to generate predictions. This uses the model directly instead of relying on the pipeline abstraction.\n"],"metadata":{"id":"6j0nBPH_aiab"}},{"cell_type":"code","source":["## import the correct module for loading models\n","# from transformers import\n","\n","# ner_model ="],"metadata":{"id":"6n2rRBU1SW_l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ner_model_outputs =\n","# pprint(ner_model_outputs)"],"metadata":{"id":"W1ZBFv4hSbxk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Interpreting Model Outputs\n","\n","The raw tensor outputs are converted to probability scores over the possible entity tags for each token.\n"],"metadata":{"id":"HcM6-5fqamNW"}},{"cell_type":"code","source":["# ner_predictions =\n","# pprint(ner_predictions)"],"metadata":{"id":"I_6RkXDkSk5c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Converting to Human-Readable Outputs\n","\n","The probabilities are parsed to extract the highest scoring entity tag per token. The start and end offsets are looked up based on the original input text.\n","\n","This mirrors the output format returned by the pipeline to extract human-readable entity, score, start, end results.\n"],"metadata":{"id":"RhnLNhd9aqso"}},{"cell_type":"code","source":["# ner_results= []\n","# for index, prediction in enumerate(ner_predictions[0]):\n","#   prediction_probability =\n","#   prediction_id =\n","#   if prediction_id > 0:\n","#     entity =\n","#     word =\n","#     start =\n","#     end =\n","#     ner_results.append({\"entity\":entity,\"score\":prediction_probability, \"index\": index, \"word\": word, \"start\": start, \"end\": end})\n","# pprint(ner_results)"],"metadata":{"id":"YEs2OO5DS5xv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# EXERCISE 3\n","* Finish the (unfinished) commented codes below\n","* Instructions start with \"##\""],"metadata":{"id":"PtaO6ILIUWZR"}},{"cell_type":"markdown","source":["# Load QA Model\n","\n","- qa_checkpoint: Specifies pretrained QA model from Hugging Face Hub to use\n","\n","- pipeline: Constructs question answering pipeline object using the QA model\n","\n","# Define Question and Context\n","\n","- question: Question text string to ask the model\n","\n","- context: Context paragraphs providing information to answer question\n","\n","# Get QA Predictions\n","\n","- qa_pipeline: Runs input question and context through model to make predictions\n","\n","- qa_results: Contains predicted answer text and confidence score\n","\n","- pprint: Prints prediction results in readable formatted output\n","\n","This code loads a pretrained QA model, defines a question and context, passes them through the pipeline to generate an answer prediction, and prints the prediction nicely formatted. The pipeline handles running the inputs through the full model to output the top answer text span and score."],"metadata":{"id":"aVah-hs3r-e3"}},{"cell_type":"code","source":["qa_checkpoint = \"deepset/roberta-base-squad2\"\n","qa_pipeline = pipeline(\"question-answering\",model=qa_checkpoint)\n","\n","question = \"What is the capital of France?\"\n","context = \"The capital of France is Paris.\"\n","\n","qa_results = qa_pipeline(question,context)\n","pprint(qa_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"49J6LAnAdcs6","executionInfo":{"status":"ok","timestamp":1689994785516,"user_tz":420,"elapsed":1585,"user":{"displayName":"Santi Adavani","userId":"01589529678393192778"}},"outputId":"043b4357-ea00-4ac4-88af-1e7aca1826b4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1m{\u001b[0m\u001b[32m'score'\u001b[0m: \u001b[1;36m0.9703434109687805\u001b[0m, \u001b[32m'start'\u001b[0m: \u001b[1;36m25\u001b[0m, \u001b[32m'end'\u001b[0m: \u001b[1;36m30\u001b[0m, \u001b[32m'answer'\u001b[0m: \u001b[32m'Paris'\u001b[0m\u001b[1m}\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9703434109687805</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'start'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'end'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Paris'</span><span style=\"font-weight: bold\">}</span>\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["Loads pretrained question answering model using AutoModelForQuestionAnswering class.\n","\n","Loads corresponding tokenizer using AutoTokenizer that was used during model training.\n","\n","Tokenizer preprocesses text to numeric ids.\n","\n","Model generates start and end logits to predict answer span."],"metadata":{"id":"bVm6T12gsvlX"}},{"cell_type":"code","source":["## import the module AutoModelForQuestionAnswering from transformer and get the model and tokenizer\n","\n","# from import\n","\n","# qa_model =\n","# qa_tokenizer ="],"metadata":{"id":"Y2lakssMbQk2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# qa_model_inputs =\n","# pprint(qa_model_inputs)"],"metadata":{"id":"kHNud9vZcCfD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# qa_model_outputs =\n","# pprint(qa_model_outputs)"],"metadata":{"id":"7bzHR-bHcQ3g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here is brief documentation for the provided code snippet:\n","\n","# Extract Logits\n","\n","- Get start and end logits from model outputs\n","\n","# Get Prediction Indices\n","\n","- Find index of maximum start and end logits\n","\n","# Decode Answer Text\n","\n","- Extract predicted answer tokens from input ids\n","\n","- Convert tokens back to text with tokenizer\n","\n","# Compute Probability\n","\n","- Take softmax of start and end logits\n","\n","- Find max joint probability of start and end\n","\n","# Format Human-Readable Output\n","\n","- Get start and end char offsets in context\n","\n","- Format into dict with score, text, offsets\n","\n","# Print Output\n","\n","- Display prediction result nicely formatted\n","\n","This takes the raw start and end logits from the model, picks the most likely start and end points, extracts the predicted answer text, computes the overall probability, and formats into a human-readable output with score and answer text."],"metadata":{"id":"3A5H_FFpu8E_"}},{"cell_type":"code","source":["start_logits, end_logits = qa_model_outputs.start_logits, qa_model_outputs.end_logits"],"metadata":{"id":"fBVdlt0lceVt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## calculate the start and end positions of the logits\n","\n","# start_pos =\n","# end_pos =\n","# pprint((start_pos,end_pos))"],"metadata":{"id":"yaVqcAlDcpk0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# answer_tokens =\n","# answer =\n","# start_probs, end_probs =\n","# probability =\n","# start =\n","# end =\n","# result = {\"score\": probability, \"answer\": answer, \"start\": start, \"end\": end}\n","# pprint(result)"],"metadata":{"id":"4swu5O59cwGe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8rE6SIrFVsaW"},"execution_count":null,"outputs":[]}]}